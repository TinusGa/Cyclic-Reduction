{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix, vstack, hstack, save_npz, load_npz, block_diag, identity, random\n",
    "from scipy.sparse.linalg import inv, spsolve, splu\n",
    "from scipy.linalg import lu\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Pool, shared_memory\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cProfile\n",
    "import pstats \n",
    "import csv\n",
    "import os \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_block_bidiagonal_nonsingular(n_blocks, block_size):\n",
    "    \"\"\"\n",
    "    Generate a nonsingular sparse lower block bidiagonal matrix in CSR format.\n",
    "\n",
    "    Parameters:\n",
    "        n_blocks (int): Number of diagonal blocks.\n",
    "        block_size (int): Size of each square block.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: The resulting nonsingular sparse matrix.\n",
    "        numpy.ndarray: The corresponding RHS vector.\n",
    "    \"\"\"\n",
    "    N = n_blocks * block_size  # Total size of the matrix\n",
    "    data, row_indices, col_indices = [], [], []\n",
    "\n",
    "    # Generate diagonal (B_i) and lower diagonal (L_i) blocks\n",
    "    for i in range(n_blocks):\n",
    "        row_offset = i * block_size\n",
    "        col_offset = i * block_size\n",
    "\n",
    "        # Ensure nonzero entries in the main diagonal block (B_i)\n",
    "        block_main = np.random.rand(block_size, block_size) + np.eye(block_size)  # Make B_i non-singular\n",
    "        for r in range(block_size):\n",
    "            for c in range(block_size):\n",
    "                val = block_main[r, c]\n",
    "                data.append(val)\n",
    "                row_indices.append(row_offset + r)\n",
    "                col_indices.append(col_offset + c)\n",
    "\n",
    "        # Lower block (L_i), ensuring nonzero entries\n",
    "        if i < n_blocks - 1:\n",
    "            row_offset = (i + 1) * block_size\n",
    "            col_offset = i * block_size\n",
    "            block_lower = np.random.rand(block_size, block_size)  # Random values ensure nonzero entries\n",
    "\n",
    "            for r in range(block_size):\n",
    "                for c in range(block_size):\n",
    "                    val = block_lower[r, c]\n",
    "                    data.append(val)\n",
    "                    row_indices.append(row_offset + r)\n",
    "                    col_indices.append(col_offset + c)\n",
    "\n",
    "    # Create sparse CSR matrix\n",
    "    sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(N, N))\n",
    "\n",
    "    # Generate a random RHS vector (column vector)\n",
    "    rhs_vector = np.random.rand(N, 1)  # Nx1 dense vector\n",
    "\n",
    "    return sparse_matrix, rhs_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:26<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "block_size = 4\n",
    "number_of_processors = 2\n",
    "\n",
    "k_list = [4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "for k in tqdm(k_list):\n",
    "    n = int(number_of_processors*2**k)\n",
    "    number_of_blocks = n + 1\n",
    "    M, f = lower_block_bidiagonal_nonsingular(number_of_blocks, block_size)\n",
    "    x = spsolve(M,f)\n",
    "    save_folder = f\"Samples_to_test\"\n",
    "    save_npz(f\"{save_folder}/n{number_of_blocks}_b{block_size}_mat.npz\",M)\n",
    "    np.save(f\"{save_folder}/n{number_of_blocks}_b{block_size}_rhs.npy\",f)\n",
    "    np.save(f\"{save_folder}/n{number_of_blocks}_b{block_size}_sol.npy\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "65\n",
      "129\n",
      "257\n",
      "513\n",
      "1025\n",
      "2049\n",
      "4097\n",
      "8193\n",
      "16385\n",
      "32769\n",
      "65537\n",
      "131073\n"
     ]
    }
   ],
   "source": [
    "for k in k_list:\n",
    "    n = int(number_of_processors*2**k)\n",
    "    number_of_blocks = n + 1\n",
    "    print(n+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_folder = \"LBBM_p4\"\n",
    "#M,f,x = load_npz(f\"{save_folder}/n_{n_blocks}_mat.npz\"), np.load(f\"{save_folder}/n_{n_blocks}_rhs.npy\"), np.load(f\"{save_folder}/n_{n_blocks}_sol.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tinus\\Desktop\\Cyclic-Reduction\\.venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\_dsolve\\linsolve.py:597: SparseEfficiencyWarning: splu converted its input to CSC format\n",
      "  return splu(A).solve\n",
      "c:\\Users\\tinus\\Desktop\\Cyclic-Reduction\\.venv\\Lib\\site-packages\\scipy\\sparse\\linalg\\_matfuncs.py:76: SparseEfficiencyWarning: spsolve is more efficient when sparse b is in the CSC matrix format\n",
      "  Ainv = spsolve(A, I)\n",
      "c:\\Users\\tinus\\Desktop\\Cyclic-Reduction\\.venv\\Lib\\site-packages\\scipy\\sparse\\_index.py:188: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil and dok are more efficient.\n",
      "  self._set_arrayXarray_sparse(i, j, x)\n"
     ]
    }
   ],
   "source": [
    "def create_full_permutation_matrix(m, block_size):\n",
    "    num_blocks = m // block_size\n",
    "    perm_order = []\n",
    "\n",
    "    # First, append all odd-indexed blocks\n",
    "    for i in range(0, num_blocks, 2):\n",
    "        perm_order.append(i)\n",
    "\n",
    "    # Then, append all even-indexed blocks\n",
    "    for i in range(1, num_blocks, 2):\n",
    "        perm_order.append(i)\n",
    "\n",
    "    data, rows, cols = [], [], []\n",
    "\n",
    "    for new_index, old_index in enumerate(perm_order):\n",
    "        start_new = new_index * block_size\n",
    "        start_old = old_index * block_size\n",
    "        for i in range(block_size):\n",
    "            data.append(1)              \n",
    "            rows.append(start_new + i)  \n",
    "            cols.append(start_old + i)  \n",
    "\n",
    "    return csr_matrix((data, (rows, cols)), shape=(m, m))\n",
    "\n",
    "\n",
    "def placeholder_name(M, f, block_size : int, processors : int):\n",
    "    \"\"\" \n",
    "    Performs Block Cyclic Reduction (BCR) in parallel for solving lower block bidiagonal systems.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : scipy.sparse.csr_matrix or numpy.ndarray\n",
    "        The coefficient matrix of size (N, N), where N = (n+1) * block_size.\n",
    "        Must be a square lower block bidiagonal matrix.\n",
    "\n",
    "    f : numpy.ndarray\n",
    "        The right-hand side (RHS) vector of size (N, 1), corresponding to Mx = f.\n",
    "\n",
    "    block_size : int\n",
    "        The size of each block in the matrix.\n",
    "\n",
    "    processors : int\n",
    "        The number of processors used for parallel block cyclic reduction.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x : numpy.ndarray\n",
    "        The solution vector of size (N, 1) satisfying Mx = f.\n",
    "    \"\"\"\n",
    "    N, L = M.shape\n",
    "    assert N == L,  f\"M must be sqaure but has dimensions {N}x{L}\"\n",
    "    n = (N - 1) // block_size\n",
    "    assert n % processors == 0, f\"M must have size (n+1)*block_size x (n+1)*block_size, where n = p * 2**k. p is not a multiple of n.\"\n",
    "    nbyp = n // processors \n",
    "    assert ((nbyp & (nbyp-1) == 0) and nbyp != 0), f\"M must have size (n+1)*block_size x (n+1)*block_size, where n = p * 2**k. n/p is not a power of two.\"\n",
    "    number_of_steps = int(np.log2(nbyp)) # Number of steps in the forward step and backward step for each processor\n",
    "\n",
    "    row_index_start = block_size\n",
    "    row_index_end = block_size*(1+nbyp)\n",
    "    col_index_start = 0\n",
    "    col_index_end = block_size*(nbyp+1)\n",
    "    \n",
    "    # Divide among the processors\n",
    "    M_k_list = []\n",
    "    f_k_list = []\n",
    "    B_k_s_list = []\n",
    "    A_k_s_list = []\n",
    "    f_k_s_list = []\n",
    "    \n",
    "    for _ in range(processors):\n",
    "        # Perform the forward step\n",
    "        M_copy = M[row_index_start:row_index_end, col_index_start:col_index_end]\n",
    "        f_copy = f[row_index_start:row_index_end]\n",
    "        M_k, f_k, B_k_s, A_k_s, f_k_s = forward_placeholder(M_copy, f_copy, block_size, processors, [], [], [])\n",
    "\n",
    "        # Store the results for inter-processor communication\n",
    "        M_k_list.append(M_k)\n",
    "        f_k_list.append(f_k)\n",
    "\n",
    "        # Store the results for the backward step\n",
    "        B_k_s_list.append(B_k_s)\n",
    "        A_k_s_list.append(A_k_s)\n",
    "        f_k_s_list.append(f_k_s)\n",
    "\n",
    "        # Update the indices for the next processor\n",
    "        row_index_start = row_index_end\n",
    "        row_index_end += nbyp*block_size \n",
    "        col_index_start = col_index_end - block_size\n",
    "        col_index_end += block_size*nbyp\n",
    "    \n",
    "    x0 = spsolve(M[:block_size,:block_size],f[:block_size]) # The master of all processors\n",
    "    base_case_x = [x0]\n",
    "\n",
    "    # Only serial part of the algorithm\n",
    "    for i in range(processors):\n",
    "        B_k = M_k_list[i][:,:block_size]\n",
    "        A_k = M_k_list[i][:,block_size:]\n",
    "        f_k = f_k_list[i]\n",
    "        x_next = spsolve(A_k,f_k.flatten()-B_k@base_case_x[i])\n",
    "        base_case_x.append(x_next)\n",
    "    \n",
    "    final_x = np.array([])\n",
    "    \n",
    "    # Perform the backward step\n",
    "    for i in range(processors):\n",
    "        B_k_s = B_k_s_list[i] \n",
    "        A_k_s = A_k_s_list[i] \n",
    "        f_k_s = f_k_s_list[i] \n",
    "\n",
    "        x_for_current_processor = backward_placeholder(B_k_s, A_k_s, f_k_s, base_case_x[i:i+2], number_of_steps, block_size, processors)\n",
    "        #x_for\n",
    "        final_x = np.concatenate((final_x, x_for_current_processor))\n",
    "\n",
    "    final_x = np.concatenate((final_x, base_case_x[-1]))\n",
    "    return final_x\n",
    "    \n",
    "    \n",
    "def forward_placeholder(M, f, block_size : int, processors : int, B_s = [], A_s = [], f_s = []):\n",
    "    n,m = M.shape\n",
    "    if n == block_size:\n",
    "        return M,f,B_s,A_s,f_s\n",
    "    \n",
    "    M_next = csr_matrix((n//2,n//2+block_size))\n",
    "    f_next = np.zeros(n//2)\n",
    "    # Do one step\n",
    "    for i in range(0,n,2*block_size):\n",
    "        # Extract block elements from input\n",
    "        B1 = M[i:i+block_size, i:i+block_size] \n",
    "        A1 = M[i:i+block_size, i + block_size: i + 2*block_size] \n",
    "        B2 = M[i + block_size: i + 2*block_size,i + block_size: i + 2*block_size ]\n",
    "        A2 = M[i + block_size: i + 2*block_size,i + 2*block_size: i + 3*block_size]\n",
    "        f1 = f[i:i+block_size]\n",
    "        f2 = f[i + block_size: i + 2*block_size]\n",
    "\n",
    "        # Store the values for the backward step\n",
    "        B_s.append(B1)\n",
    "        A_s.append(A1)\n",
    "        f_s.append(f1)\n",
    "\n",
    "        # Compute inverses and values for the next depth. This is equivalent to removing all odd indices from the input\n",
    "        B2_inv = inv(B2)\n",
    "        A1_inv = inv(A1)\n",
    "        new_B1 = A1_inv@B1\n",
    "        new_A1 = -B2_inv@A2\n",
    "        new_f1 = A1_inv@f1 - B2_inv@f2\n",
    "\n",
    "        # Set the new values to obtain a reduced system of half the original size\n",
    "        j = i//2\n",
    "        M_next[j:j+block_size,j:j+block_size] = new_B1\n",
    "        M_next[j:j+block_size,j+block_size:j+2*block_size] = new_A1\n",
    "        f_next[j:j+block_size] = new_f1.flatten()\n",
    "\n",
    "    # Recursively apply the same procedure\n",
    "    return forward_placeholder(M_next,f_next,block_size,processors,B_s,A_s,f_s)\n",
    "\n",
    "def backward_placeholder(B_s, A_s, f_s, x_s, number_of_steps : int, block_size : int, processors : int):\n",
    "    x_result = x_s[0]\n",
    "    power = 0\n",
    "    for i in range(number_of_steps-1,-1,-1):\n",
    "        j = -(2**power - 1) if power > 0 else None\n",
    "        k = -(2**(power+1) - 1)\n",
    "\n",
    "        B = B_s[k:j]\n",
    "        A = A_s[k:j]\n",
    "        f = f_s[k:j]\n",
    "\n",
    "        A_for_solve = block_diag(A, format='csr')\n",
    "        B_for_solve = block_diag(B, format='csr')\n",
    "        f_for_solve = np.concatenate(f).flatten()\n",
    "        x_for_solve = x_result.copy()   \n",
    "\n",
    "        x_new = spsolve(A_for_solve,f_for_solve - B_for_solve@x_for_solve)\n",
    "\n",
    "        x_result = np.concatenate((x_result,x_new))\n",
    "        Q = create_full_permutation_matrix(x_result.shape[0], block_size)\n",
    "        x_result = Q.T@x_result\n",
    "        power += 1\n",
    "    return x_result\n",
    "    \n",
    "\n",
    "x_sol = placeholder_name(M,f,block_size=block_size,processors=p)\n",
    "print(np.allclose(x_sol,x,atol=1e-10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
