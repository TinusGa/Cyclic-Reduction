{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, csc_matrix, lil_matrix, vstack, hstack, save_npz, load_npz, block_diag, identity, random\n",
    "from scipy.sparse.linalg import inv, spsolve, splu\n",
    "from scipy.linalg import lu\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Pool, shared_memory\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cProfile\n",
    "import pstats \n",
    "import csv\n",
    "import os \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_block_bidiagonal_nonsingular(n_blocks, block_size):\n",
    "    \"\"\"\n",
    "    Generate a nonsingular sparse lower block bidiagonal matrix in CSR format.\n",
    "\n",
    "    Parameters:\n",
    "        n_blocks (int): Number of diagonal blocks.\n",
    "        block_size (int): Size of each square block.\n",
    "\n",
    "    Returns:\n",
    "        scipy.sparse.csr_matrix: The resulting nonsingular sparse matrix.\n",
    "        numpy.ndarray: The corresponding RHS vector.\n",
    "    \"\"\"\n",
    "    N = n_blocks * block_size  # Total size of the matrix\n",
    "    data, row_indices, col_indices = [], [], []\n",
    "\n",
    "    # Generate diagonal (B_i) and lower diagonal (L_i) blocks\n",
    "    for i in range(n_blocks):\n",
    "        row_offset = i * block_size\n",
    "        col_offset = i * block_size\n",
    "\n",
    "        # Ensure nonzero entries in the main diagonal block (B_i)\n",
    "        block_main = np.random.rand(block_size, block_size) + np.eye(block_size)  # Make B_i non-singular\n",
    "        for r in range(block_size):\n",
    "            for c in range(block_size):\n",
    "                val = block_main[r, c]\n",
    "                data.append(val)\n",
    "                row_indices.append(row_offset + r)\n",
    "                col_indices.append(col_offset + c)\n",
    "\n",
    "        # Lower block (L_i), ensuring nonzero entries\n",
    "        if i < n_blocks - 1:\n",
    "            row_offset = (i + 1) * block_size\n",
    "            col_offset = i * block_size\n",
    "            block_lower = np.random.rand(block_size, block_size)  # Random values ensure nonzero entries\n",
    "\n",
    "            for r in range(block_size):\n",
    "                for c in range(block_size):\n",
    "                    val = block_lower[r, c]\n",
    "                    data.append(val)\n",
    "                    row_indices.append(row_offset + r)\n",
    "                    col_indices.append(col_offset + c)\n",
    "\n",
    "    # Create sparse CSR matrix\n",
    "    sparse_matrix = csr_matrix((data, (row_indices, col_indices)), shape=(N, N))\n",
    "\n",
    "    # Generate a random RHS vector (column vector)\n",
    "    rhs_vector = np.random.rand(N, 1)  # Nx1 dense vector\n",
    "\n",
    "    return sparse_matrix, rhs_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 4 # no. of processors\n",
    "k = 2 # recursion/iteration depth\n",
    "n = int(p*2**k)\n",
    "\n",
    "n_blocks = n + 1\n",
    "block_size = 2\n",
    "\n",
    "# M, f = lower_block_bidiagonal_nonsingular(n_blocks, block_size)\n",
    "# x = spsolve(M,f)\n",
    "\n",
    "# save_folder = \"LBBM_p4\" # Lower block bidiagonal matrix for 4 processors\n",
    "# save_npz(f\"{save_folder}/n_{n_blocks}_mat.npz\",M)\n",
    "# np.save(f\"{save_folder}/n_{n_blocks}_rhs.npy\",f)\n",
    "# np.save(f\"{save_folder}/n_{n_blocks}_sol.npy\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"LBBM_p4\"\n",
    "M,f,x = load_npz(f\"{save_folder}/n_{n_blocks}_mat.npz\"), np.load(f\"{save_folder}/n_{n_blocks}_rhs.npy\"), np.load(f\"{save_folder}/n_{n_blocks}_sol.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward step finished!\n",
      "Forward step finished!\n",
      "Forward step finished!\n",
      "Forward step finished!\n",
      "[ 0.48647425 -0.20084005 -0.21812064  0.65115813 -0.08274303  0.26345255\n",
      " -0.16983722  0.30626582 -0.03114629  0.28064602]\n",
      "[ 0.48647425 -0.20084005  0.23309244  0.00811299 -0.08274303  0.26345255\n",
      " -0.16983722  0.30626582 -0.21812064  0.65115813  0.88325422 -0.07304672\n",
      "  0.48174632 -0.1657839   0.43910117  0.11724197  0.23124714 -0.56470413\n",
      "  0.92287657  0.03407044  0.10228898  0.46162783  0.06601929  0.23358886\n",
      " -0.04730871  0.39700067  0.30031906  0.40821593  0.22053257 -0.22680817\n",
      "  0.12370639  0.02582541  0.43580205 -0.234097  ]\n"
     ]
    }
   ],
   "source": [
    "def placeholder_name(M, f, block_size : int, processors : int):\n",
    "    \"\"\" \n",
    "    Performs Block Cyclic Reduction (BCR) in parallel for solving lower block bidiagonal systems.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    M : scipy.sparse.csr_matrix or numpy.ndarray\n",
    "        The coefficient matrix of size (N, N), where N = (n+1) * block_size.\n",
    "        Must be a square lower block bidiagonal matrix.\n",
    "\n",
    "    f : numpy.ndarray\n",
    "        The right-hand side (RHS) vector of size (N, 1), corresponding to Mx = f.\n",
    "\n",
    "    block_size : int\n",
    "        The size of each block in the matrix.\n",
    "\n",
    "    processors : int\n",
    "        The number of processors used for parallel block cyclic reduction.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    x : numpy.ndarray\n",
    "        The solution vector of size (N, 1) satisfying Mx = f.\n",
    "    \"\"\"\n",
    "    N, L = M.shape\n",
    "    assert N == L,  f\"M must be sqaure but has dimensions {N}x{L}\"\n",
    "    n = (N - 1) // block_size\n",
    "    assert n % processors == 0, f\"M must have size (n+1)*block_size x (n+1)*block_size, where n = p * 2**k. p is not a multiple of n.\"\n",
    "    nbyp = n // processors \n",
    "    assert ((nbyp & (nbyp-1) == 0) and nbyp != 0), f\"M must have size (n+1)*block_size x (n+1)*block_size, where n = p * 2**k. n/p is not a power of two.\"\n",
    "\n",
    "    row_index_start = block_size\n",
    "    row_index_end = block_size*(1+nbyp)\n",
    "    col_index_start = 0\n",
    "    col_index_end = block_size*(nbyp+1)\n",
    "    \n",
    "    # Divide among the processors\n",
    "    M_k_list = []\n",
    "    f_k_list = []\n",
    "    B_k_s_list = []\n",
    "    A_k_s_list = []\n",
    "    f_k_s_list = []\n",
    "    \n",
    "    for _ in range(processors):\n",
    "        # Perform the forward step\n",
    "        M_copy = M[row_index_start:row_index_end, col_index_start:col_index_end]\n",
    "        f_copy = f[row_index_start:row_index_end]\n",
    "        M_k, f_k, B_k_s, A_k_s, f_k_s = forward_placeholder(M_copy, f_copy, block_size, processors, [], [], [])\n",
    "\n",
    "        # Store the results for inter-processor communication\n",
    "        M_k_list.append(M_k)\n",
    "        f_k_list.append(f_k)\n",
    "\n",
    "        # Store the results for the backward step\n",
    "        B_k_s_list.append(B_k_s)\n",
    "        A_k_s_list.append(A_k_s)\n",
    "        f_k_s_list.append(f_k_s)\n",
    "\n",
    "        # Update the indices for the next processor\n",
    "        row_index_start = row_index_end\n",
    "        row_index_end += nbyp*block_size \n",
    "        col_index_start = col_index_end - block_size\n",
    "        col_index_end += block_size*nbyp\n",
    "    \n",
    "    x0 = spsolve(M[:block_size,:block_size],f[:block_size]) # The master of all processors\n",
    "    base_case_x = [x0]\n",
    "\n",
    "    # Only serial part of the algorithm\n",
    "    for i in range(processors):\n",
    "        B_k = M_k_list[i][:,:block_size]\n",
    "        A_k = M_k_list[i][:,block_size:]\n",
    "        f_k = f_k_list[i]\n",
    "        x_next = spsolve(A_k,f_k.flatten()-B_k@base_case_x[i])\n",
    "        base_case_x.append(x_next)\n",
    "    \n",
    "    # Perform the backward step\n",
    "    for i in range(processors):\n",
    "        B_k_s = B_k_s_list[i] \n",
    "        A_k_s = A_k_s_list[i] \n",
    "        f_k_s = f_k_s_list[i] \n",
    "\n",
    "        some_res = backward_placeholder(B_k_s, A_k_s, f_k_s, base_case_x[i:i+2], block_size, processors)\n",
    "        #print(some_res)\n",
    "        break\n",
    "    \n",
    "    \n",
    "def forward_placeholder(M, f, block_size : int, processors : int, B_s = [], A_s = [], f_s = []):\n",
    "    n,m = M.shape\n",
    "    if n == block_size:\n",
    "        print(f\"Forward step finished!\")\n",
    "        return M,f,B_s,A_s,f_s\n",
    "    \n",
    "    M_next = csr_matrix((n//2,n//2+block_size))\n",
    "    f_next = np.zeros(n//2)\n",
    "    # Do one step\n",
    "    for i in range(0,n,2*block_size):\n",
    "        # Extract block elements from input\n",
    "        B1 = M[i:i+block_size, i:i+block_size] \n",
    "        A1 = M[i:i+block_size, i + block_size: i + 2*block_size] \n",
    "        B2 = M[i + block_size: i + 2*block_size,i + block_size: i + 2*block_size ]\n",
    "        A2 = M[i + block_size: i + 2*block_size,i + 2*block_size: i + 3*block_size]\n",
    "        f1 = f[i:i+block_size]\n",
    "        f2 = f[i + block_size: i + 2*block_size]\n",
    "\n",
    "        # Store the values for the backward step\n",
    "        B_s.append(B1)\n",
    "        A_s.append(A1)\n",
    "        f_s.append(f1)\n",
    "\n",
    "        # Compute inverses and values for the next depth. This is equivalent to removing all odd indices from the input\n",
    "        B2_inv = inv(B2)\n",
    "        A1_inv = inv(A1)\n",
    "        new_B1 = A1_inv@B1\n",
    "        new_A1 = -B2_inv@A2\n",
    "        new_f1 = A1_inv@f1 - B2_inv@f2\n",
    "\n",
    "        # B_s.append(new_B1)\n",
    "        # A_s.append(new_A1)\n",
    "        # f_s.append(new_f1)\n",
    "\n",
    "        # Set the new values to obtain a reduced system of half the original size\n",
    "        j = i//2\n",
    "        M_next[j:j+block_size,j:j+block_size] = new_B1\n",
    "        M_next[j:j+block_size,j+block_size:j+2*block_size] = new_A1\n",
    "        f_next[j:j+block_size] = new_f1.flatten()\n",
    "\n",
    "    # Recursively apply the same procedure\n",
    "    return forward_placeholder(M_next,f_next,block_size,processors,B_s,A_s,f_s)\n",
    "\n",
    "def backward_placeholder(B_s, A_s, f_s, x_s, block_size : int, processors : int):\n",
    "    x_result = np.concatenate((x_s[0],x_s[1]))\n",
    "    x_next = x_s[0]\n",
    "\n",
    "    for i in range(len(B_s)-1,-1,-1):\n",
    "        B = B_s[i]\n",
    "        A = A_s[i]\n",
    "        f = f_s[i].flatten()\n",
    "        x_next = spsolve(A,f - B@x_next)\n",
    "        x_result = np.concatenate((x_result, x_next))\n",
    "    print(x_result.flatten())\n",
    "    return x_result.flatten()\n",
    "    \n",
    "\n",
    "np.set_printoptions(precision=8, suppress=True)\n",
    "placeholder_name(M,f,block_size=block_size,processors=p)\n",
    "print(x)\n",
    "# selected_numbers = zip(x[0::4], x[1::4])\n",
    "# selected_numbers = np.array(list(selected_numbers)).flatten()\n",
    "# print(selected_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[4, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[7, 8]\n"
     ]
    }
   ],
   "source": [
    "abba = [1,2,3,4,5,6,7,8]\n",
    "\n",
    "for i in range(len(abba)-1):\n",
    "    print(abba[i:i+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About this repository\n",
    "\n",
    "This repository attempts to implement parallel cyclic reduction for the solution of block tridiagonal linear systems. In other words, solving $Mx=f$ faaast. This is a work in progress and only some of the code is stable. \n",
    "\n",
    "The first implementation reconstructed the algorithm proposed by P, Amodio and N. Mastronardi in [this paper](https://doi.org/10.1016/0167-8191(93)90031-F), together with [this paper](https://doi.org/10.1016/0898-1221(93)90109-9) also by P. Amodio. The corresponding code can be found under CR_v1/cyclic_reduction_v8 (yes it took 8 versions to complete). If you want to test the code, good luck. Some tests for various problem sizes are provided, but you'll have to navigate the code yourself. I recently moved some files to clean the repository so running the aforementioned script will most likely fail, but it shouldn't be too hard to fix.\n",
    "\n",
    "Currently, work is focused on impementing parallel cyclic reduction for the solution of lower block bidiagonal linear systems. This implementation is self made, so it will be interesting to see how it turns out. Most of the work is complete, with only the final step (back-substitution) unfinished. Hopefully, this won't take too long, inshallah. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
